
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2. What is Fairness? &#8212; Fairness &amp; Algorithmic Decision Making</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e7340bb3dbd8dde6db86f25597f54a1b.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="3. Harm, Discrimination, and Measurement" href="03-harms.html" />
    <link rel="prev" title="1. Introduction" href="01-introduction.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Fairness & Algorithmic Decision Making</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Fairness and Algorithmic Decision Making
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01-introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   2. What is Fairness?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-harms.html">
   3. Harm, Discrimination, and Measurement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04-compas.html">
   4. COMPAS Recidivism Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05-parity-measures.html">
   5. Parity Measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-interpreting-parity-measures.html">
   6. Interpreting Parity Measures
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   7. Bibliography
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/02-frameworks.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-medical-decision-making">
   2.1. Example: Medical decision making
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#notions-of-fairness-welfare-and-justice">
   2.2. Notions of fairness, welfare, and justice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#utilitarianism">
   2.3. Utilitarianism
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#utilitarianism-and-machine-learning">
     2.3.1. Utilitarianism and machine learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#distributive-justice">
   2.4. Distributive Justice
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#formal-equality-of-opportunity">
     2.4.1. Formal Equality of Opportunity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fair-equality-of-opportunity">
     2.4.2. Fair Equality of Opportunity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#luck-egalitarianism">
     2.4.3. Luck Egalitarianism
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="what-is-fairness">
<h1><span class="section-number">2. </span>What is Fairness?<a class="headerlink" href="#what-is-fairness" title="Permalink to this headline">¶</a></h1>
<p>Throughout the course, we will take a practical view of understanding
fairness in algorithmic decision making: how can we identify potential
issues with a system, understand its impact on people with whom it
interacts, and what should we do about it.</p>
<p>This lecture will introduce terms and concepts from philosophy that
will help us approach these questions. We will briefly discuss terms
like fairness, justice, welfare, equality, equity, bias, and
discrimination and how they frame discussions about decision making as
a society.</p>
<div class="section" id="example-medical-decision-making">
<h2><span class="section-number">2.1. </span>Example: Medical decision making<a class="headerlink" href="#example-medical-decision-making" title="Permalink to this headline">¶</a></h2>
<p>As an introductory example, we’ll examine the issues involved in
rationing medical care, specifically ventilators, during the COVID-19
pandemic <span id="id1">[<a class="reference internal" href="bibliography.html#id9"><span>SCW20</span></a>]</span>.</p>
<p>People with severe cases of coronavirus experience trouble breathing
and medical treatment often consisted of putting the patient on a
ventilator for weeks at a time. During the height of the COVID-19
pandemic, many hospitals filled beyond capacity and experienced a
shortage of ventilators. The decision became: which patients receive
access to a ventilator?</p>
<ul class="simple">
<li><p>Should only those with the highest chance at recovery receive a
ventilator?</p></li>
</ul>
<p>This option attempts to <em>optimize</em> the existing (scarce) stock of
ventilators and falls into a <em>utilitarian</em> point of view. However,
there are a few objections to this:</p>
<ul class="simple">
<li><p>What if ventilators are sitting unused in anticipation of future
patients with a higher chance of recovery?</p></li>
<li><p>How is “chance of recovery” measured? Those with a better chance of
recovery may only be in better health because of prior access to
quality health-care.</p></li>
</ul>
<p>Other options might suggest that patients have, in some sense, an
equal right the needed ventilators:</p>
<ul class="simple">
<li><p>Should patients entering the hospital receive ventilators on a
‘first-come first-served’ basis?</p></li>
<li><p>Should anyone in need, regardless of access to health-care, have an
equal chance of receiving a ventilator?</p></li>
</ul>
<p>In practice, healthcare systems blend these two points of view
<span id="id2">[<a class="reference internal" href="bibliography.html#id9"><span>SCW20</span></a>]</span>. We will look at these concepts, and continuing
analyzing this example through this lecture.</p>
</div>
<div class="section" id="notions-of-fairness-welfare-and-justice">
<h2><span class="section-number">2.2. </span>Notions of fairness, welfare, and justice<a class="headerlink" href="#notions-of-fairness-welfare-and-justice" title="Permalink to this headline">¶</a></h2>
<p>Initially, we will focus on concepts of fairness, welfare, and justice
in the context of allocative decision making by a state or
organization. This entry point is reasonable, as</p>
<ol class="simple">
<li><p>algorithmic decision making systems usually make decisions for
<em>others</em>, and</p></li>
<li><p>discussion of allocative decisions are plentiful, accessible, and
important.</p></li>
</ol>
<p>At the end of this lecture, we’ll explore how these notions apply in
other settings.</p>
</div>
<div class="section" id="utilitarianism">
<h2><span class="section-number">2.3. </span>Utilitarianism<a class="headerlink" href="#utilitarianism" title="Permalink to this headline">¶</a></h2>
<p>First developed by Jeremy Bentham and John Stuart Mill,
<em>utilitarianism</em> is a doctrine that states:</p>
<ol class="simple">
<li><p>Only the consequences of actions determine what’s right and wrong
(<em>consequentialism</em>).</p></li>
<li><p>The right action is one that ‘provides the greatest benefit to the
most people.’ (<em>utilitarianism</em>)</p></li>
</ol>
<p>The perspective of maximizing aggregate social welfare has a notable
consequence: a person may be treated poorly for the good of
others. The thought-experiment illustrating is consequence is
the famous trolley problem:</p>
<blockquote>
<div><p>A trolley is heading toward five people working on the track.
You can pull a lever and redirect the trolley to a track that has
only one worker.
Would you pull the lever, deciding to kill one worker to save the other five?</p>
</div></blockquote>
<p>A utilitarian might describe the utility of pulling the lever to be
five times greater than not.</p>
<div class="admonition-question admonition">
<p class="admonition-title">Question</p>
<p>What are the reasons you wouldn’t pull the lever?</p>
<ul class="simple">
<li><p>Which of these reasons are objections to the consequentialist
component? (part 1)</p></li>
<li><p>Which of these reasons are objections to the utilitarian component?
(part 2)</p></li>
<li><p>Are there reasons for objecting to pulling the lever that are
consistent with utilitarianism? (e.g. how the total utility is calculated).</p></li>
</ul>
</div>
<p>The ventilator example illustrates a similar observation:</p>
<ul class="simple">
<li><p>Would you hold back the use of a ventilator for a patient that might
arrive later who is more likely to recover because of it (or recover
more quickly)?</p></li>
<li><p>Would you take away the ventilator from a patient already using it
if another patient that might receive greater benefit from it needs
one as well?</p></li>
</ul>
<p>Even for the committed utilitarian, the answers to these questions
depend on how you define ‘benefit’ and calculate the utility of making
a given decision. The study by Savulescu et al. examine some of these
choices, including maximizing number of lives saved, the aggregrate
number of years-of-life saved (valuing healthy over frail; young over
old).</p>
<p>Public health professionals working in healthcare systems make these
estimates daily, in a multitude of ways. Of course, these
professionals also take into account legal, professional, and moral
reasons in making their choices of benefit and utility. We will
address these later.</p>
<div class="section" id="utilitarianism-and-machine-learning">
<h3><span class="section-number">2.3.1. </span>Utilitarianism and machine learning<a class="headerlink" href="#utilitarianism-and-machine-learning" title="Permalink to this headline">¶</a></h3>
<p>This theory aligns with the basic organization of a machine learning
powered decision making system. Fitting a model optimizes a loss
function over the training set. The features are used to approximate
potential benefits (often captured via a label), while the loss
function corresponds to the utility. By default, a model makes better
decisions when it optimizes loss of the entire training set.</p>
<div class="admonition-question admonition">
<p class="admonition-title">Question</p>
<p>Sketch the structure of a model that decides whether an new patient
should receive a ventilator. Begin with the following components:</p>
<ol class="simple">
<li><p>A model that, given information about the patient (place of
residence, age, medical history), predicts the number of days they
would use a ventilator.</p></li>
<li><p>The current state of the healthcare system (number of patients
arriving per day, with given medical information).</p></li>
<li><p>A utility function to optimize (think about what this might be).</p></li>
</ol>
<p>What are some morally problematic behaviors of this model? What do you
think it should or should not use in making its decisions?</p>
</div>
</div>
</div>
<div class="section" id="distributive-justice">
<h2><span class="section-number">2.4. </span>Distributive Justice<a class="headerlink" href="#distributive-justice" title="Permalink to this headline">¶</a></h2>
<p>A theory of distributive justice describes ‘a just distribution of
relevant goods in a society.’ The qualifier of ‘just’ is in response
to utilitarianism’s unjust distribution of goods in the name of
maximizing the aggregate welfare of the people. What qualifiers and
limitations should be placed on such distribution to make them morally
acceptable?</p>
<p>Three closely related limits that address just distribution are
equality, priority, and sufficiency <span id="id3">[<a class="reference internal" href="bibliography.html#id10"><span>Val03</span></a>]</span>. Limiting optimal distribution by
a condition that ensures, in a broad sense, people benefit equally is
described by theories of egalitarianism. Prioritarianism attempts to
maximize goods <em>first</em> according to those most in need. Sufficiency
places a floor on the sufficient distribution of goods, so that all
basic needs are met, after which goods are distributed to maximize
welfare.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The term ‘goods’ here is broadly defined as anything that positively
contributes to a persons welfare (tangible goods, happiness,
opportunity).</p>
</div>
<p>In the most naive way, an egalitarian theory might limit the
distribution of goods to be equal for everyone. However, in light of
the broad notion of ‘goods’, any such theory would be unreasonably
restrictive. Moreover, even if one only requires equality of total
utility for each person, one has to confront the effect that
drastically different choices in life make on that sum-total. One way
of approaching this issue is by stipulating that everyone has a right
to the same <em>opportunities</em> in life.</p>
<p>The remainder of this section follows <span id="id4">[<a class="reference internal" href="bibliography.html#id11"><span>Arn15</span></a>]</span>.</p>
<div class="section" id="formal-equality-of-opportunity">
<h3><span class="section-number">2.4.1. </span>Formal Equality of Opportunity<a class="headerlink" href="#formal-equality-of-opportunity" title="Permalink to this headline">¶</a></h3>
<p>Equality of Opportunity (EO) is a condition that seeks to restrict
distribution of goods in a fair way. There are several notions of EO
that refine the condition of ‘equal’ in ways that lead to different
results in practice. Various notions of EO are codified in law in
countries around the world.</p>
<p>Formal equality of opportunity requires that a benefit is theoretically
available to anyone, regardless of their background. For example, an open
job position that satisfies Formal EO requires the employer to open
the pool of applicants to everyone and that those applications be
consider based on merits (as opposed to, for example, nepotism).</p>
<p>In the example of the distribution of ventilators, formal equality of
opportunity is not violated. Indeed, all patients that enter the
hospital are considered for treatment with a ventilator; the choice of
who receives one is based purely on ‘merit’ (conditions that are
equally applied to all individuals). It is not the case that
ventilators are only reserved for donors to the hospital.</p>
</div>
<div class="section" id="fair-equality-of-opportunity">
<h3><span class="section-number">2.4.2. </span>Fair Equality of Opportunity<a class="headerlink" href="#fair-equality-of-opportunity" title="Permalink to this headline">¶</a></h3>
<p>One limitation of Formal Equality of Opportunity (FEO) is that while
the distribution of goods is open to all, the ability to take
advantage of such an opportunity may <em>effectively</em> be
non-existent. For example, a job may be available through passing an
arbitrary examination that only very wealthy pass (because only they
can afford the training). While this job is theoretically available to
everyone (satisfying formal EO), it in practice is only available to
the very wealthy.</p>
<p>John Rawls developed the concept of “fair equality of opportunity”
that modified the EO statement so that, “assuming there is a
distribution of natural assets, those who are at the same level of
talent and ability, and have the same willingness to use them, should
have the same prospects of success regardless of their initial place
in the social system.”</p>
<p><span id="id5">[<a class="reference internal" href="bibliography.html#id11"><span>Arn15</span></a>]</span>.</p>
<p>To illustrate this ideal, Rawls envisioned a though-experiment he
coined ‘The Veil of Ignorance’: imagine that you are proposing a certain
distribution of goods in a hypothetical society. Would you consider
the distribution just if you did not know who you would be in this
society?</p>
<p>The Veil of Ignorance separates (dis)advantages given by circumstances
like to whom you were born from those circumstances that come from
conscious choice throughout life.</p>
<p>In the example of ventilator distribution, a patient born with a
disability should have an equal claim to a ventilator as someone
without a disability, even if that disability affects complicates
potential recovery.</p>
<p>In <span id="id6">[<a class="reference internal" href="bibliography.html#id12"><span>HLG+19</span></a>]</span>, the authors translate FEO into mathematical
terms as follows. Suppose</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(e\)</span> refers to the choices that one puts into life (talent, effort,
ambition). These are, according to FEO, the legitimate sources of
inequality that arise in the world.</p></li>
<li><p><span class="math notranslate nohighlight">\(c\)</span> refers to circumstances beyond ones control. <span class="math notranslate nohighlight">\(c\)</span> captures the
conditions from birth that may affect life’s outcomes
(e.g. socio-economic status at birth).</p></li>
<li><p><span class="math notranslate nohighlight">\(F(\cdot|c, e)\)</span> is the cumulative distribution of utility at fixed
effort <span class="math notranslate nohighlight">\(e\)</span> and circumstance <span class="math notranslate nohighlight">\(c\)</span>.</p></li>
</ul>
<p>The Rawlsian FEO states that for all circumstances <span class="math notranslate nohighlight">\(c, c'\)</span> and a fixed
<span class="math notranslate nohighlight">\(e\)</span>:</p>
<div class="math notranslate nohighlight">
\[
F(\cdot|c, e) = F(\cdot|c', e)
\]</div>
<p>That is, the cumulative utility depends only on <span class="math notranslate nohighlight">\(e\)</span>.</p>
</div>
<div class="section" id="luck-egalitarianism">
<h3><span class="section-number">2.4.3. </span>Luck Egalitarianism<a class="headerlink" href="#luck-egalitarianism" title="Permalink to this headline">¶</a></h3>
<p>Conceptions of Equality of Opportunity dictate conditions under which
it is just to gain an advantage over others in society. On the other hand,
Luck Egalitarianism demands that differences in the goods that people
accumulate should only be determined by choices people make and not by
differences in unchosen circumstance <em>throughout</em> their life
(i.e. luck).</p>
<p>In the example of ventilator distribution, a patient systematically
denied access to the healthcare system (e.g. by being born into
poverty) may have a <em>greater</em> claim to a ventilator (in spite of being
in poorer health), so that the expected benefit equals those with easy
access to healthcare (and thus more likely to be healthy, arrive at
the hospital less sick, etc). This is untrue of FEO.</p>
<p>Luck egalitarianism is also called ‘The Level Playing
Field’ ideal because of its relative view of legitamate sources of
inequality. That is, if two people share similar circumstances, then
equal ‘effort’ should result in equal utility.</p>
<p>Quantitatively, as derived in <span id="id7">[<a class="reference internal" href="bibliography.html#id12"><span>HLG+19</span></a>]</span>, suppose</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(c\)</span> refers to circumstances beyond ones control (i.e. ‘luck’),</p></li>
<li><p>that <span class="math notranslate nohighlight">\(0 \leq \pi \leq 1\)</span> is the <span class="math notranslate nohighlight">\(\pi\)</span>th quantile of the
<em>distribution of effort</em> of individuals under circumstances <span class="math notranslate nohighlight">\(c\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(F(\cdot|c, \pi)\)</span> is the cumulative distribution of utility at
circumstance <span class="math notranslate nohighlight">\(c\)</span>and effort-quantile <span class="math notranslate nohighlight">\(\pi\)</span>.</p></li>
</ul>
<p>Luck Egalitarianism is satisfied if for all <span class="math notranslate nohighlight">\(\pi\in[0,1]\)</span> and for any
two circumstances <span class="math notranslate nohighlight">\(c,c'\)</span>:</p>
<div class="math notranslate nohighlight">
\[
F(\cdot|c, \pi) = F(\cdot|c', \pi)
\]</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="01-introduction.html" title="previous page"><span class="section-number">1. </span>Introduction</a>
    <a class='right-next' id="next-link" href="03-harms.html" title="next page"><span class="section-number">3. </span>Harm, Discrimination, and Measurement</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Aaron Fraenkel<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>